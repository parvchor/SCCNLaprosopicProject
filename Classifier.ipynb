{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.base import clone\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (cross_val_score, GridSearchCV, KFold, LeaveOneOut,\n",
    "                                     ShuffleSplit, StratifiedKFold, train_test_split)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All file paths: ['Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_theta.csv','Data\\\\bandpower_delta.csv','Data\\\\bandpower_alpha.csv', 'Data\\\\bandpower_beta.csv', 'Data\\\\bandpower_gamma.csv', 'Data\\\\coherence_delta.csv','Data\\\\coherence_theta.csv','Data\\\\coherence_alpha.csv','Data\\\\coherence_beta.csv', 'Data\\\\coherence_gamma.csv']\n",
    "\n",
    "X_files = ['Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_theta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_delta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_alpha.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_beta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\bandpower_gamma.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\coherence_delta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\coherence_theta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\coherence_alpha.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\coherence_beta.csv', 'Data\\\\Data20SecondOverlapAllChannels\\\\coherence_gamma.csv']\n",
    "Y_files = 'Data\\\\Data20SecondOverlapAllChannels\\\\stress_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EEG features\n",
    "X_dfs = [pd.read_csv(file) for file in X_files]\n",
    "\n",
    "\n",
    "Y_dfs = pd.read_csv(Y_files)\n",
    "Y_dfs = pd.DataFrame(Y_dfs)\n",
    "stressThreshold = 6.\n",
    "Y_dfs = (Y_dfs >= stressThreshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (863, 1500)\n",
      "Y shape (863, 1)\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(X_dfs[0])\n",
    "combined_rows = [pd.concat([df.iloc[i] for df in X_dfs], ignore_index=True) for i in range(num_rows)]\n",
    "\n",
    "\n",
    "X_dfs = pd.concat(combined_rows, axis=1).transpose()\n",
    "\n",
    "\n",
    "#Drop subject 7(Unconforming Data)\n",
    "X_dfs = X_dfs.drop(range(723, 872))\n",
    "X_dfs = X_dfs.reset_index(drop=True)\n",
    "Y_dfs = Y_dfs.drop(range(723, 872))\n",
    "Y_dfs = Y_dfs.reset_index(drop=True)\n",
    "\n",
    "#Drop subject 5(Unconforming Data)\n",
    "X_dfs = X_dfs.drop(range(468, 585))\n",
    "X_dfs = X_dfs.reset_index(drop=True)\n",
    "Y_dfs = Y_dfs.drop(range(468, 585))\n",
    "Y_dfs = Y_dfs.reset_index(drop=True)\n",
    "\n",
    "print(\"X shape\", X_dfs.shape)\n",
    "print(\"Y shape\", Y_dfs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s(No stress): 425\n",
      "Number of 1s(Stress): 438\n"
     ]
    }
   ],
   "source": [
    "#Find how many stress and no stress samples we have.\n",
    "\n",
    "value_counts = Y_dfs.value_counts()\n",
    "\n",
    "num_zeros = value_counts.get(0, 0)\n",
    "num_ones = value_counts.get(1, 0)\n",
    "\n",
    "print(f\"Number of 0s(No stress): {num_zeros}\")\n",
    "print(f\"Number of 1s(Stress): {num_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looCV(x, y):\n",
    "    ##LOOCV\n",
    "\n",
    "    # Instantiate the SVM classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "    # Instantiate LeaveOneOut\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    # Initialize a list to store the accuracy for each fold\n",
    "    accuracies = []\n",
    "\n",
    "    # Loop over each train-test split\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        # Split the data\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        \n",
    "        # Train the classifier\n",
    "        svm_classifier.fit(X_train, y_train.ravel())\n",
    "        \n",
    "        # Make a prediction for the test set\n",
    "        y_pred = svm_classifier.predict(X_test)\n",
    "        \n",
    "        # Calculate the accuracy for this fold\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Calculate the mean accuracy across all folds\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "\n",
    "    print(f\"Mean LOOCV Accuracy: {mean_accuracy}\")\n",
    "\n",
    "def kFoldCV(x, y):\n",
    "    #K-Fold\n",
    "\n",
    "\n",
    "    # Define the classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "    # Choose the number of folds\n",
    "    k = 10  \n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    scores = cross_val_score(svm_classifier, x, y.values.ravel(), cv=k, scoring='accuracy')\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Accuracy scores for each fold: {scores}\")\n",
    "    print(f\"Mean accuracy across all folds: {scores.mean()}\")\n",
    "    print(f\"Standard deviation of the accuracy across all folds: {scores.std()}\")\n",
    "\n",
    "def kFoldStratCV(x,y):\n",
    "        #Stratified K-Fold\n",
    "\n",
    "    # Initialize the classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "    # Define the number of folds\n",
    "    k = 10\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "    # Initialize an array to store the accuracy for each fold\n",
    "    accuracies = []\n",
    "\n",
    "    # Perform Stratified K-Fold Cross-Validation\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Train the classifier\n",
    "        svm_classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy for this fold\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Calculate the mean and standard deviation of the accuracies\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {std_accuracy}\")\n",
    "\n",
    "def shuffleSplitCV(x, y):\n",
    "        #Shuffle Split\n",
    "\n",
    "    # Initialize the classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "    # Define the number of iterations and test set size\n",
    "    n_splits = 100  \n",
    "    test_size = 0.2  \n",
    "\n",
    "    # Create the ShuffleSplit object\n",
    "    cv = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0)\n",
    "\n",
    "    # Initialize an array to store the accuracy for each split\n",
    "    accuracies = []\n",
    "\n",
    "    # Perform the splits, train the model, and calculate accuracy\n",
    "    for train_index, test_index in cv.split(x):\n",
    "        # Ensure we're using iloc to access rows by integer location\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        svm_classifier.fit(X_train, y_train.values.ravel())\n",
    "        y_pred = svm_classifier.predict(X_test)\n",
    "        \n",
    "        # Calculate and store the accuracy\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Calculate the mean and standard deviation of the accuracy\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "    print(f\"Standard Deviation of Accuracy: {std_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidations(x,y):\n",
    "    looCV(x,y)\n",
    "    print(\"Kfold: \\n\\n\\n\")\n",
    "    kFoldCV(x,y)\n",
    "    print(\"KfoldStrat: \\n\\n\\n\")\n",
    "    kFoldStratCV(x,y)\n",
    "    print(\"Shuffle Split: \\n\\n\\n\")\n",
    "    shuffleSplitCV(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No feature Selection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LOOCV Accuracy: 0.7960602549246814\n",
      "Accuracy scores for each fold: [0.56321839 0.55172414 0.57471264 0.44186047 0.58139535 0.51162791\n",
      " 0.51162791 0.58139535 0.72093023 0.54651163]\n",
      "Mean accuracy across all folds: 0.5585004009623095\n",
      "Standard deviation of the accuracy across all folds: 0.06775358894533128\n",
      "Mean Accuracy: 0.5585004009623095\n",
      "Standard Deviation of Accuracy: 0.06775358894533128\n",
      "Mean Accuracy: 0.7913294797687861\n",
      "Standard Deviation of Accuracy: 0.029377585571267198\n"
     ]
    }
   ],
   "source": [
    "crossValidations(X_dfs, Y_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecurrentFeatureElim(x,y,n):\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "\n",
    "    # Number of RFE iterations and the number of features to select\n",
    "    n_features_to_select = n  \n",
    "\n",
    "    # Initialize a DataFrame to store the selection count for each feature\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=n_features_to_select, step=1)\n",
    "\n",
    "    # Fit RFE\n",
    "    rfe.fit(x, y.values.ravel())\n",
    "\n",
    "    X_transformed = rfe.transform(x)\n",
    "    X_transformed_df = pd.DataFrame(X_transformed)\n",
    "\n",
    "    return X_transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use RFE for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LOOCV Accuracy: 0.9177288528389339\n",
      "Kfold: \n",
      "\n",
      "\n",
      "\n",
      "Accuracy scores for each fold: [0.73563218 0.79310345 0.93103448 0.90697674 0.73255814 0.79069767\n",
      " 0.8255814  0.76744186 0.87209302 0.96511628]\n",
      "Mean accuracy across all folds: 0.8320235231221599\n",
      "Standard deviation of the accuracy across all folds: 0.07833258898391907\n",
      "KfoldStrat: \n",
      "\n",
      "\n",
      "\n",
      "Mean Accuracy: 0.8320235231221599\n",
      "Standard Deviation of Accuracy: 0.07833258898391907\n",
      "Shuffle Split: \n",
      "\n",
      "\n",
      "\n",
      "Mean Accuracy: 0.9115028901734106\n",
      "Standard Deviation of Accuracy: 0.019545693834765118\n"
     ]
    }
   ],
   "source": [
    "X_dfs_RFE = RecurrentFeatureElim(X_dfs,Y_dfs,200)\n",
    "\n",
    "crossValidations(X_dfs_RFE, Y_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecurrentFeatureElimCV(x,y):\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "    # Initialize a DataFrame to store the selection count for each feature\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "\n",
    "    # Fit RFE\n",
    "    rfecv.fit(x, y.values.ravel())\n",
    "\n",
    "    X_transformed = rfecv.transform(x)\n",
    "    X_transformed_df = pd.DataFrame(X_transformed)\n",
    "\n",
    "    return X_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_dfs_RFECV \u001b[38;5;241m=\u001b[39m \u001b[43mRecurrentFeatureElimCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_dfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[192], line 9\u001b[0m, in \u001b[0;36mRecurrentFeatureElimCV\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m rfecv \u001b[38;5;241m=\u001b[39m RFECV(estimator\u001b[38;5;241m=\u001b[39msvc, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39mStratifiedKFold(\u001b[38;5;241m10\u001b[39m), scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Fit RFE\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mrfecv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m rfecv\u001b[38;5;241m.\u001b[39mtransform(x)\n\u001b[0;32m     12\u001b[0m X_transformed_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_transformed)\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:752\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    749\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    750\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 752\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    758\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:753\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    749\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    750\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m    752\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m--> 753\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    755\u001b[0m )\n\u001b[0;32m    757\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    758\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:35\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     33\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[0;32m     34\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO(SLEP6): pass score_params here\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mscores_\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:311\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 311\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    314\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    315\u001b[0m     estimator,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    317\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    318\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\parvc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_dfs_RFECV = RecurrentFeatureElimCV(X_dfs,Y_dfs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
